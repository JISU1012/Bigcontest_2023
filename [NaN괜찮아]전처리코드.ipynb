{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"jrY0s2nZLdQH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f114945-d7b4-4939-8549-95fc5483c630","executionInfo":{"status":"ok","timestamp":1695755374678,"user_tz":-540,"elapsed":31578,"user":{"displayName":"이채윤","userId":"10158698688563022551"}}},"id":"jrY0s2nZLdQH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"SH6GONFwgGqz","metadata":{"id":"SH6GONFwgGqz"},"outputs":[],"source":["!pip install openai\n","!pip install langchain\n","!pip install xgboost"]},{"cell_type":"code","execution_count":null,"id":"a3de21c1","metadata":{"id":"a3de21c1"},"outputs":[],"source":["import openai\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","from langchain.prompts.few_shot import FewShotPromptTemplate\n","from langchain.prompts.prompt import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain.agents import create_pandas_dataframe_agent\n","from langchain.llms import OpenAI\n","from langchain.chat_models import ChatOpenAI\n","from sklearn.model_selection import train_test_split\n","import matplotlib\n","\n","matplotlib.rcParams['font.family'] ='Malgun Gothic'\n","\n","matplotlib.rcParams['axes.unicode_minus'] =False"]},{"cell_type":"markdown","source":["# Few-Shot Learning"],"metadata":{"id":"hWZ9yriVh7j-"},"id":"hWZ9yriVh7j-"},{"cell_type":"code","execution_count":null,"id":"0677a3ce","metadata":{"id":"0677a3ce"},"outputs":[],"source":["# OpenAI API 키 설정\n","api_key = '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'  # 본인의 API 키로 바꿔주세요\n","# OpenAI API 클라이언트 초기화\n","openai.api_key = api_key\n","\n","os.environ['OPENAI_API_KEY'] = api_key"]},{"cell_type":"code","execution_count":null,"id":"970d2d35","metadata":{"id":"970d2d35"},"outputs":[],"source":["code_examples = [\n","\n","    {\"question\": \"Please provide a Python code without line breaks, spaces, and comments for performing classification using Random Forest.\",\n","    \"answer\": \"\"\"from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","X = data.data\n","y = data.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_classifier.fit(X_train, y_train)\n","y_pred = rf_classifier.predict(X_test)\n","    \"\"\"\n","    },\n","    {\"question\": \"Please provide Python code without line breaks, spaces, and comments for performing classification using a logistic regression model.\",\n","    \"answer\": \"\"\"from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","    \"\"\"\n","    }\n","\n","]"]},{"cell_type":"code","execution_count":null,"id":"59729dc9","metadata":{"id":"59729dc9"},"outputs":[],"source":["code_example_prompt = PromptTemplate(template = \"My Question: {question}\\nAI Answer: {answer}\",\n","                               input_variables = [\"question\", \"answer\"])\n","\n","\n","\n","# print(code_example_prompt.format(**code_examples[0]))"]},{"cell_type":"code","execution_count":null,"id":"07db513d","metadata":{"id":"07db513d"},"outputs":[],"source":["few_shot_code_prompt = FewShotPromptTemplate(\n","    examples=code_examples,\n","    example_prompt=code_example_prompt,\n","    suffix=\"Question: {input}\",\n","    input_variables=[\"input\"]\n",")\n","\n","# print(few_shot_code_prompt.format(input=\"Please provide a Python code for performing classification using XGBoost.\"))"]},{"cell_type":"code","execution_count":null,"id":"346b4d5b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"346b4d5b","outputId":"90245475-f1c6-4e63-9f7e-1d80c0eea0d1","executionInfo":{"status":"ok","timestamp":1695755417221,"user_tz":-540,"elapsed":8,"user":{"displayName":"이채윤","userId":"10158698688563022551"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n","  warnings.warn(\n"]}],"source":["llm = OpenAI(temperature=0, max_tokens=256, model_name = \"gpt-3.5-turbo\")"]},{"cell_type":"markdown","id":"62b66543-af82-407a-95fe-8ea51f669a17","metadata":{"id":"62b66543-af82-407a-95fe-8ea51f669a17"},"source":["# Data load"]},{"cell_type":"code","source":["user_spec = pd.read_csv('/content/drive/MyDrive/2023BigCon/user_spec.csv')\n","loan_result = pd.read_csv('/content/drive/MyDrive/2023BigCon/loan_result.csv')\n","# user_spec.isnull().sum()"],"metadata":{"id":"Ps1L8BQ6st_8"},"id":"Ps1L8BQ6st_8","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Processing"],"metadata":{"id":"TKsAscdzPNay"},"id":"TKsAscdzPNay"},{"cell_type":"markdown","source":["---\n","## loan_result processing\n","- 형 변환 수행\n","- 결측치 처리 수행"],"metadata":{"id":"oECz3qVDiEQW"},"id":"oECz3qVDiEQW"},{"cell_type":"code","execution_count":null,"id":"39359e1f-6fd0-4d58-8d44-8d84d937961c","metadata":{"id":"39359e1f-6fd0-4d58-8d44-8d84d937961c"},"outputs":[],"source":["code_chain = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","Given data loan_result,please provide code to process these requests in order with loan_result.\n","\n","Answer with code, no comments\n","1. Please Delete rows where column 'loan_limit' value is null.\n","2. Convert the 'loanapply_insert_time' column to datetime format\n","3. Delete rows where column 'bank_id' value is 16 .\n","\n","Answer with code, no comments\n","\"\"\"\n","code_response = code_chain.run(question)\n","# print(code_response)"]},{"cell_type":"code","execution_count":null,"id":"17d8e58e-cb94-44d6-9f9e-ea92ba0363e2","metadata":{"id":"17d8e58e-cb94-44d6-9f9e-ea92ba0363e2"},"outputs":[],"source":["code_chain2 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","\n","1. Remove 'gender'column.\n","2. Convert the 'insert_time' column to datetime format.\n","3. Convert the 'company_enter_month' column to string format.\n","4. Take the first six characters and append '01' to rows where 'company_enter_month' value is not missing .\n","    Do not append '01' if the  'company_enter_month' value is missing.\n","    If there are rows where company_enter_month value is 'nan01', convert the values 'nan01' to Nan.\n","    Finally convert company_enter_month column to datetime data type.\n","\n","Do not include comments.\n","\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response2 = code_chain2.run(question)\n","# print(code_response2)"]},{"cell_type":"markdown","source":["---\n","## user_spec processing"],"metadata":{"id":"Ng6Qw_wiiKkA"},"id":"Ng6Qw_wiiKkA"},{"cell_type":"markdown","source":["### 'company_enter_month', 'birth_year' 결측치 처리"],"metadata":{"id":"dKefLso8QnFS"},"id":"dKefLso8QnFS"},{"cell_type":"code","execution_count":null,"id":"d74486f1-66f5-4f08-b536-d8a760f056a6","metadata":{"id":"d74486f1-66f5-4f08-b536-d8a760f056a6"},"outputs":[],"source":["code_chain3 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","1.Replace missing values in the 'company_enter_month' column with values by same 'user_id'.\n"," Fill in missing values in a DataFrame column named 'company_enter_month' by using a dictionary that maps user IDs to their respective company entry months.\n"," Check each row in the DataFrame, and if the 'company_enter_month' is missing (NaN),then\n"," Replace it with the entry month associated with the user ID from the dictionary.\n"," If no entry exists for the user ID, remain as NaN.\n","2.In the same way ,Replace missing values 'birth_year' column with values by same 'user_id'.\n","\n","Answer only with code, no comments\n","'''\n","code_response3 = code_chain3.run(question)\n","# print(code_response3)"]},{"cell_type":"markdown","source":["---\n","### 파생변수 생성\n","- employment_period\n","- age\n","- rehabilitation"],"metadata":{"id":"UiTEKFyXiWPG"},"id":"UiTEKFyXiWPG"},{"cell_type":"code","execution_count":null,"id":"15888d9e-7cf2-45fe-85e7-f8d9cc30e950","metadata":{"id":"15888d9e-7cf2-45fe-85e7-f8d9cc30e950"},"outputs":[],"source":["code_chain4 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","1. Create two new variables:\n","    'employment_period': Represents the number of days an individual has been employed.\n","                        Calculate by taking the difference between the 'insert_time'and 'company_enter_month'. Extract the number of days using .dt.days.\n","                        If there's negative values,replace negative values with NaN (missing values)\n","    'age': Represents the age of individuals. Calculate by subtracting their 'birth_year' from the year component of 'insert_time', which gives us their age in years.\n","2. Remove column 'company_enter_month', 'birth_year'\n","3. Include only individuals who are 19 years old or older or Nan values.\n","\n","Answer only with code, no comments\n","'''\n","code_response4 = code_chain4.run(question)\n","# print(code_response4)"]},{"cell_type":"code","execution_count":null,"id":"683171c8-2674-4eac-bf9a-b3495aabda1b","metadata":{"id":"683171c8-2674-4eac-bf9a-b3495aabda1b"},"outputs":[],"source":["code_chain5 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","1.amt_idx = np.where(user_spec.columns == 'existing_loan_amt')[0][0]\n","  cnt_idx = np.where(user_spec.columns == 'existing_loan_cnt')[0][0]\n","  Find the indices where both 'existing_loan_cnt' and 'existing_loan_amt' are NaN and save index to 'nan_idx'.\n","  Replace the values to 0 for user_spec.iloc[nan_idx, amt_idx]\n","  Replace the values to 0 for user_spec.iloc[nan_idx, cnt_idx]\n","\n","2. Remove rows where 'income_type' is NaN.\n","3.Impute missing values in 'yearly_income' with the mean from the same 'user_id'.\n","Answer only with code, no comments\n","'''\n","code_response5 = code_chain5.run(question)\n","# print(code_response5)"]},{"cell_type":"code","execution_count":null,"id":"fd91c3c4-eb30-4804-a126-d3599d766b41","metadata":{"id":"fd91c3c4-eb30-4804-a126-d3599d766b41"},"outputs":[],"source":["code_chain6 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","Set 'rehabilitation' values as follows:\n","- If 'personal_rehabilitation_yn' is 1 and 'personal_rehabilitation_complete_yn' is 0, set 'rehabilitation' to \"Ongoing.\"\n","- If 'personal_rehabilitation_yn' is 1 and 'personal_rehabilitation_complete_yn' is 1, set 'rehabilitation' to \"Completed.\"\n","- If 'personal_rehabilitation_yn' is 0, set 'rehabilitation' to \"Not Applicable.\"\n","- If both 'personal_rehabilitation_yn' and 'personal_rehabilitation_complete_yn' are missing (NaN), set 'rehabilitation' to \"Unknown.\"\n"," '''\n","code_response6 = code_chain6.run(question)\n","# print(code_response6)"]},{"cell_type":"markdown","source":["---\n","### 'credit_score' 결측치 처리\n","- XGBRegressor\n"],"metadata":{"id":"_iysFDRXih5J"},"id":"_iysFDRXih5J"},{"cell_type":"code","execution_count":null,"id":"b4234068-3f07-48cf-bc32-6473332b8a9e","metadata":{"id":"b4234068-3f07-48cf-bc32-6473332b8a9e"},"outputs":[],"source":["code_chain7 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","1.Remove column 'personal_rehabilitation_yn' and 'personal_rehabilitation_complete_yn'.\n","2.Convert column 'rehabilitation' into categorical format.\n","3. Fill missing values in column 'credit_score'\n"," Create 'unique_credit_scores' column. Count the number of unique credit scores per user_id and store this value in unique_credit_scores.\n"," For rows where 'credit_score' is missing and 'unique_credit_scores' is 1, replace 'credit_score' with the value from that single unique credit score in the group.\n"," For rows where 'credit_score' is missing and 'unique_credit_scores' is greater than 1, replace 'credit_score' with the mean value of credit scores within that user group.\n","\n"," '''\n","code_response7 = code_chain7.run(question)\n","# print(code_response7)"]},{"cell_type":"code","execution_count":null,"id":"a4dcb74f-baa2-4801-949c-61a5d5d489bd","metadata":{"id":"a4dcb74f-baa2-4801-949c-61a5d5d489bd"},"outputs":[],"source":["code_chain8 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","1. Drop column 'unique_credit_scores'\n","2. Convert 'income_type','houseown_type','employment_type','purpose','rehabilitation' columns to categorical data types\n","3. Please Delete rows where column 'yearly_income' value is null.\n","\n"," '''\n","code_response8 = code_chain8.run(question)\n","# print(code_response8)"]},{"cell_type":"code","execution_count":null,"id":"cb384c8f-3a07-49e8-a044-01f3150825e5","metadata":{"id":"cb384c8f-3a07-49e8-a044-01f3150825e5"},"outputs":[],"source":["code_chain9 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = '''\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","Please provide a Python code without line breaks, spaces, and comments.\n","\n","Fill Missing 'credit_score' Using Train-Test Split and XGBoost Regression\n","The process involves splitting the data into training (with non-null 'credit_score') and testing (with missing 'credit_score') sets.\n","Then use an XGBoost Regressor model to predict the missing 'credit_score' values based on other relevant features.\n","\n","1. Split the data into 'train' and 'test' sets based on the presence of 'credit_score' values and define feature sets ('train_X' and 'test_X') and target variables ('train_y' and 'test_y') for the model.\n","Use columns 'yearly_income','employment_type','houseown_type','existing_loan_cnt','existing_loan_amt','rehabilitation','age' and 'credit_score'\n","3. Create an XGBoost Regressor model ('xgb_re_model') with specific configurations,enable_categorical=True, tree_method='hist'.\n","4. Train the model on the 'train' set.\n","5. Use the trained model to predict missing 'credit_score' values in the 'test' set and storing the predictions in 'y_pred'.\n","6. Assign the predicted 'credit_score' values to the 'test' copy set(test_copy).\n","7. Concatenate the 'train' and 'test_copy' sets to update the 'user_spec' DataFrame with the imputed 'credit_score' values.\n","'''\n","code_response9 = code_chain9.run(question)\n","# print(code_response9)"]},{"cell_type":"markdown","id":"89a77950","metadata":{"id":"89a77950"},"source":["---\n","### 'age' 결측치 처리\n","- XGBClassifier"]},{"cell_type":"code","execution_count":null,"id":"9e51d323","metadata":{"id":"9e51d323"},"outputs":[],"source":["code_chain10 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframe is user_spec, please provide a Python code without line breaks, spaces, and comments:\n","\n","Convert the 'age' variable into increments of 10 from the teens to the nineties to create a user-defined function, and create a new variable called 'cluster_age'(range of variable starts from 0) excluding the upper bound of the range.\n","\n","And then, Set the category variable 'cluster_age' value to '9', If the 'age' value is missing.\n","Convert the 'cluster_age, income_type, employment_type, houseown_type, purpose, rehabilitation' column to a categorical data type.\n","\"\"\"\n","code_response10 = code_chain10.run(question)\n","# print(code_response10)"]},{"cell_type":"code","execution_count":null,"id":"4aef28a7","metadata":{"id":"4aef28a7"},"outputs":[],"source":["code_chain11 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframe is user_spec which is already loaded, please provide a Python code without line breaks, spaces, and comments:\n","\n","Using the enable_categorical=True 'XGBClassifier' histogram-based training method with GPU from the 'XGBoost' package, use the data where 'age' is not missing, excluding the 'age', 'user_id','application_id', 'insert_time' variables as the training data, and use the data where 'age' is missing, with the 'age', 'application_id', 'user_id', 'insert_time','cluster_age' variables removed, as the test data to predict 'cluster_age' in the test data.\n","do not use 'train_test_split'.\n","\n","\n","Apply the predicted values to the 'cluster_age' variable in the original data frame.\n","Do not include comments.\n","\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response11 = code_chain11.run(question)\n","# print(code_response11)"]},{"cell_type":"code","execution_count":null,"id":"631a97fd","metadata":{"id":"631a97fd"},"outputs":[],"source":["code_chain12 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframe is user_spec, please provide a Python code without line breaks, spaces, and comments:\n","\n","Convert the 'cluster_age' column to a int data type.\n","Update the age column with the value of 20 + 10*cluster_age for the rows with missing age values.\n","Remove the 'cluster_age' column from the dataset named user_spec.\n","\"\"\"\n","code_response12 = code_chain12.run(question)\n","# print(code_response12)"]},{"cell_type":"markdown","id":"502b7ceb","metadata":{"id":"502b7ceb"},"source":["---\n","###'existing_loan_amt', 'employment_period' 결측 처리\n","- MICE\n"]},{"cell_type":"code","execution_count":null,"id":"e4521c9d","metadata":{"id":"e4521c9d"},"outputs":[],"source":["# user_spec = pd.read_csv('/content/drive/MyDrive/user_spec_result_age.csv', index_col=0)\n","# user_spec.info()"]},{"cell_type":"code","execution_count":null,"id":"a73f07fb","metadata":{"id":"a73f07fb"},"outputs":[],"source":["code_chain13 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframe is user_spec, please provide a Python code without line breaks, spaces, and comments:\n","\n","Follow the instructions in the following order to implement multiple imputation using ExtraTreesRegressor and IterativeImputer.\n","Exclude the variables 'age', 'application_id', 'user_id', 'insert_time', 'income_type', 'employment_type', 'houseown_type', 'purpose', 'rehabilitation'.\n","Fit an IterativeImputer with ExtraTreesRegressor to the data with the desired columns removed. Perform a maximum of 10 iterations with a convergence tolerance set at 0.1, excluding complete columns from the replacement process, and do not use 'fit_transform'.\n","Transform on the data with only the desired columns removed and Do not drop duplicates. Then, save it as 'result'.\n","\"\"\"\n","\n","question = question.strip('\\n')\n","\n","code_response13 = code_chain13.run(question)\n","# print(code_response13)"]},{"cell_type":"code","execution_count":null,"id":"ca899339","metadata":{"id":"ca899339"},"outputs":[],"source":["code_chain14 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","Please provide a Python code without line breaks, spaces, and comments:\n","\n","Create a DataFrame using the data already stored in 'result', with the column names 'credit_score', 'yearly_income', 'desired_amount', 'existing_loan_cnt', 'existing_loan_amt', 'employment_period'.\n","Replace the 'existing_loan_amt' and 'employment_period' columns in 'user_spec' with the values from the created DataFrame.\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response14 = code_chain14.run(question)\n","# print(code_response14)"]},{"cell_type":"markdown","id":"29062688","metadata":{"id":"29062688"},"source":["---\n","### Bank_id clustering"]},{"cell_type":"code","execution_count":null,"id":"d038d883","metadata":{"id":"d038d883"},"outputs":[],"source":["code_chain15 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The dataframes are 'user_spec' and 'loan_result' which are already loaded, please provide a Python code without line breaks, spaces, and comments:\n","\n","Replace the values of 'purpose', which are 'LIVING', 'ETC', 'HOUSEDEPOSIT', 'BUYHOUSE', 'BUYCAR', 'INVEST', 'BUSINESS', 'SWITCHLOAN', with '생활비', '기타', '전월세보증금', '주택구입', '자동차구입', '투자', '사업자금', '대환대출' respectively.\n","Merge the two dataframes based on 'application_id' to create a new dataframe called 'user_loan,' and retain only those rows where 'loan_limit' is not missing.\n","Perform k-means clustering using only 'loan_limit' and 'loan_rate' as features. Set the initial number of clusters to 5, the number of initial centroid attempts to 10, and use random initialization.\n","Create a new column 'bank_cluster' to store the clustering predictions. Then remove 'bank_id', and 'product_id' from user_loan.\n","\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response15 = code_chain15.run(question)\n","# print(code_response15)"]},{"cell_type":"markdown","id":"bddeea20","metadata":{"id":"bddeea20"},"source":["---\n","### 파생변수 생성\n","- 'loan_limit_per'\n","- 'loan_rate_per'"]},{"cell_type":"code","execution_count":null,"id":"9527378d","metadata":{"id":"9527378d"},"outputs":[],"source":["code_chain16 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The given dataframe is 'user_loan'(you do not have to road the dataframes), please provide a Python code without line breaks, spaces, and comments:\n","\n","Calculate the minimum value of loan_rate for each application_id and create a new variable called loan_rate_min with application_id as its identifier, and create a new variable loan_rate_per by dividing loan_rate_min by (loan_rate + 0.0000001).\n","Calculate the maximum value of loan_limit for each application_id and create a new variable called loan_limit_max with application_id as its identifier, and create a new variable loan_limit_per by dividing loan_limit by (loan_limit_max + 0.0000001).\n","Remove 'loan_rate_min', 'loan_limit_max' columns from the dataset.\n","\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response16 = code_chain16.run(question)\n","# print(code_response16)"]},{"cell_type":"markdown","id":"6b660982","metadata":{"id":"6b660982"},"source":["---\n","## Data split"]},{"cell_type":"code","execution_count":null,"id":"50b23119","metadata":{"id":"50b23119"},"outputs":[],"source":["code_chain17 = LLMChain(llm=llm, prompt=few_shot_code_prompt)\n","\n","question = \"\"\"\n","The given dataframe is 'user_loan'(you do not have to road the dataframes), please provide a Python code without line breaks, spaces, and comments:\n","\n","Change the loanapply_insert_time variable to a datetime variable.\n","Create a variable 'month' from the month of 'loanapply_insert_time'.\n","Refer to the values of the 'month' variable. If it is June, designate it as the test data.\n","\"For the remaining data, use the 'month' variable as a reference and split it into train and validation data in an 80:20 ratio while maintaining the proportions of months 3, 4, and 5. In the end, you will have train_data, valid_data, and test_data.\n","\"\"\"\n","question = question.strip('\\n')\n","\n","code_response17 = code_chain17.run(question)\n","# print(code_response17)"]},{"cell_type":"code","source":["try:\n","    final_answer = \"\\n\".join([code_response, code_response2, code_response3, code_response5, code_response6, code_response7, code_response8, code_response9, code_response10, code_response11, code_response12, code_response13\n","                              , code_response14, code_response15, code_response16, code_response17])\n","    exec(final_answer)\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"oXbbauUwnT7O"},"id":"oXbbauUwnT7O","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_data.to_pickle('/content/drive/MyDrive/2023BigCon/2023Data/train_data_final.pkl')\n","# valid_data.to_pickle('/content/drive/MyDrive/2023BigCon/2023Data/valid_data_final.pkl')\n","# test_data.to_pickle('/content/drive/MyDrive/2023BigCon/2023Data/test_data_final.pkl')"],"metadata":{"id":"F5shK6XKiCjC"},"id":"F5shK6XKiCjC","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 최종 Data Processing 분석서"],"metadata":{"id":"ZJdAlyNlbhwe"},"id":"ZJdAlyNlbhwe"},{"cell_type":"code","source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0,\n","    )\n","    return response.choices[0].message[\"content\"]"],"metadata":{"id":"nYTQIV9FejEQ"},"id":"nYTQIV9FejEQ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_answer = \"\\n\".join([code_response, code_response2, code_response3, code_response5, code_response6, code_response7, code_response8, code_response9, code_response10, code_response11, code_response12, code_response13\n","                          , code_response14, code_response15, code_response16, code_response17])\n","print(final_answer)"],"metadata":{"id":"HG3mGjYtZkng","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695756434105,"user_tz":-540,"elapsed":8,"user":{"displayName":"이채윤","userId":"10158698688563022551"}},"outputId":"6ea1b8fe-1285-4cf7-f0b9-b5f4282b5259"},"id":"HG3mGjYtZkng","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["import pandas as pd\n","\n","# 1. Delete rows where column 'loan_limit' value is null\n","loan_result = loan_result.dropna(subset=['loan_limit'])\n","\n","# 2. Convert the 'loanapply_insert_time' column to datetime format\n","loan_result['loanapply_insert_time'] = pd.to_datetime(loan_result['loanapply_insert_time'])\n","\n","# 3. Delete rows where column 'bank_id' value is 16\n","loan_result = loan_result[loan_result['bank_id'] != 16]\n","import pandas as pd\n","user_spec.drop('gender', axis=1, inplace=True)\n","user_spec['insert_time'] = pd.to_datetime(user_spec['insert_time'])\n","user_spec['company_enter_month'] = user_spec['company_enter_month'].astype(str)\n","user_spec['company_enter_month'] = user_spec['company_enter_month'].apply(lambda x: x[:6] + '01' if x != 'nan' else x)\n","user_spec['company_enter_month'] = user_spec['company_enter_month'].replace('nan01', pd.NaT)\n","user_spec['company_enter_month'] = pd.to_datetime(user_spec['company_enter_month'])\n","user_spec['company_enter_month'] = user_spec['company_enter_month'].fillna(user_spec['user_id'].map(user_spec.groupby('user_id')['company_enter_month'].first()))\n","user_spec['birth_year'] = user_spec['birth_year'].fillna(user_spec['user_id'].map(user_spec.groupby('user_id')['birth_year'].first()))\n","1. amt_idx=np.where(user_spec.columns=='existing_loan_amt')[0][0];cnt_idx=np.where(user_spec.columns=='existing_loan_cnt')[0][0];nan_idx=np.where((user_spec['existing_loan_cnt'].isnull()) & (user_spec['existing_loan_amt'].isnull()))[0];user_spec.iloc[nan_idx,amt_idx]=0;user_spec.iloc[nan_idx,cnt_idx]=0\n","2. user_spec = user_spec.dropna(subset=['income_type'])\n","3. user_spec['yearly_income'] = user_spec.groupby('user_id')['yearly_income'].transform(lambda x: x.fillna(x.mean()))\n","user_spec['rehabilitation'] = np.where((user_spec['personal_rehabilitation_yn'] == 1) & (user_spec['personal_rehabilitation_complete_yn'] == 0), \"Ongoing\", \n","                                        np.where((user_spec['personal_rehabilitation_yn'] == 1) & (user_spec['personal_rehabilitation_complete_yn'] == 1), \"Completed\", \n","                                                 np.where(user_spec['personal_rehabilitation_yn'] == 0, \"Not Applicable\", \n","                                                          np.where(pd.isnull(user_spec['personal_rehabilitation_yn']) & pd.isnull(user_spec['personal_rehabilitation_complete_yn']), \"Unknown\", \"\"))))\n","import pandas as pd\n","user_spec.drop(['personal_rehabilitation_yn', 'personal_rehabilitation_complete_yn'], axis=1, inplace=True)\n","user_spec['rehabilitation'] = user_spec['rehabilitation'].astype('category')\n","user_spec['credit_score'].fillna(user_spec.groupby('user_id')['credit_score'].transform('mean'), inplace=True)\n","user_spec['unique_credit_scores'] = user_spec.groupby('user_id')['credit_score'].transform('nunique')\n","user_spec.loc[user_spec['credit_score'].isnull() & (user_spec['unique_credit_scores'] == 1), 'credit_score'] = user_spec.groupby('user_id')['credit_score'].transform('first')\n","user_spec.loc[user_spec['credit_score'].isnull() & (user_spec['unique_credit_scores'] > 1), 'credit_score'] = user_spec.groupby('user_id')['credit_score'].transform('mean')\n","import pandas as pd\n","user_spec.drop('unique_credit_scores', axis=1, inplace=True)\n","user_spec['income_type'] = user_spec['income_type'].astype('category')\n","user_spec['houseown_type'] = user_spec['houseown_type'].astype('category')\n","user_spec['employment_type'] = user_spec['employment_type'].astype('category')\n","user_spec['purpose'] = user_spec['purpose'].astype('category')\n","user_spec['rehabilitation'] = user_spec['rehabilitation'].astype('category')\n","user_spec.dropna(subset=['yearly_income'], inplace=True)\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBRegressor\n","\n","train = user_spec[user_spec['credit_score'].notnull()]\n","test = user_spec[user_spec['credit_score'].isnull()]\n","\n","train_X = train[['yearly_income', 'employment_type', 'houseown_type', 'existing_loan_cnt', 'existing_loan_amt', 'rehabilitation', 'age', 'credit_score']]\n","train_y = train['credit_score']\n","\n","test_X = test[['yearly_income', 'employment_type', 'houseown_type', 'existing_loan_cnt', 'existing_loan_amt', 'rehabilitation', 'age', 'credit_score']]\n","\n","xgb_re_model = XGBRegressor(enable_categorical=True, tree_method='hist')\n","xgb_re_model.fit(train_X, train_y)\n","\n","y_pred = xgb_re_model.predict(test_X)\n","\n","test_copy = test.copy()\n","test_copy['credit_score'] = y_pred\n","\n","user_spec = pd.concat([train, test_copy])\n","import pandas as pd\n","def convert_age(age):\n","    if age < 20:\n","        return 0\n","    elif age < 30:\n","        return 1\n","    elif age < 40:\n","        return 2\n","    elif age < 50:\n","        return 3\n","    elif age < 60:\n","        return 4\n","    elif age < 70:\n","        return 5\n","    elif age < 80:\n","        return 6\n","    elif age < 90:\n","        return 7\n","    else:\n","        return 8\n","\n","user_spec['cluster_age'] = user_spec['age'].apply(convert_age)\n","user_spec['cluster_age'].fillna(9, inplace=True)\n","user_spec['cluster_age'] = user_spec['cluster_age'].astype('category')\n","user_spec['income_type'] = user_spec['income_type'].astype('category')\n","user_spec['employment_type'] = user_spec['employment_type'].astype('category')\n","user_spec['houseown_type'] = user_spec['houseown_type'].astype('category')\n","user_spec['purpose'] = user_spec['purpose'].astype('category')\n","user_spec['rehabilitation'] = user_spec['rehabilitation'].astype('category')\n","import pandas as pd\n","import xgboost as xgb\n","\n","# Training data\n","train_data = user_spec[user_spec['age'].notnull()].drop(['age', 'user_id', 'application_id', 'insert_time'], axis=1)\n","train_labels = train_data['cluster_age']\n","train_data = train_data.drop('cluster_age', axis=1)\n","\n","# Test data\n","test_data = user_spec[user_spec['age'].isnull()].drop(['age', 'application_id', 'user_id', 'insert_time', 'cluster_age'], axis=1)\n","\n","# XGBoost classifier\n","xgb_classifier = xgb.XGBClassifier(enable_categorical=True, tree_method='gpu_hist')\n","\n","# Training\n","xgb_classifier.fit(train_data, train_labels)\n","\n","# Prediction\n","test_data['cluster_age'] = xgb_classifier.predict(test_data)\n","\n","# Apply predicted values to original dataframe\n","user_spec.loc[user_spec['age'].isnull(), 'cluster_age'] = test_data['cluster_age']\n","import pandas as pd\n","user_spec['cluster_age'] = user_spec['cluster_age'].astype(int)\n","user_spec['age'] = user_spec['age'].fillna(20 + 10*user_spec['cluster_age'])\n","user_spec = user_spec.drop('cluster_age', axis=1)\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.ensemble import ExtraTreesRegressor\n","\n","columns_to_exclude = ['age', 'application_id', 'user_id', 'insert_time', 'income_type', 'employment_type', 'houseown_type', 'purpose', 'rehabilitation']\n","desired_columns = [col for col in user_spec.columns if col not in columns_to_exclude]\n","\n","imputer = IterativeImputer(estimator=ExtraTreesRegressor(), max_iter=10, tol=0.1, skip_complete=True)\n","imputer.fit(user_spec[desired_columns])\n","result = imputer.transform(user_spec[desired_columns])\n","import pandas as pd\n","result = pd.DataFrame(result, columns=['credit_score', 'yearly_income', 'desired_amount', 'existing_loan_cnt', 'existing_loan_amt', 'employment_period'])\n","user_spec['existing_loan_amt'] = result['existing_loan_amt']\n","user_spec['employment_period'] = result['employment_period']\n","import pandas as pd\n","from sklearn.cluster import KMeans\n","\n","user_spec['purpose'].replace({'LIVING': '생활비', 'ETC': '기타', 'HOUSEDEPOSIT': '전월세보증금', 'BUYHOUSE': '주택구입', 'BUYCAR': '자동차구입', 'INVEST': '투자', 'BUSINESS': '사업자금', 'SWITCHLOAN': '대환대출'}, inplace=True)\n","\n","user_loan = pd.merge(user_spec, loan_result, on='application_id')\n","user_loan = user_loan.dropna(subset=['loan_limit'])\n","\n","features = user_loan[['loan_limit', 'loan_rate']]\n","\n","kmeans = KMeans(n_clusters=5, n_init=10, init='random')\n","kmeans.fit(features)\n","\n","user_loan['bank_cluster'] = kmeans.predict(features)\n","user_loan = user_loan.drop(['bank_id', 'product_id'], axis=1)\n","import pandas as pd\n","user_loan['loan_rate_min'] = user_loan.groupby('application_id')['loan_rate'].transform('min')\n","user_loan['loan_rate_per'] = user_loan['loan_rate_min'] / (user_loan['loan_rate'] + 0.0000001)\n","user_loan['loan_limit_max'] = user_loan.groupby('application_id')['loan_limit'].transform('max')\n","user_loan['loan_limit_per'] = user_loan['loan_limit'] / (user_loan['loan_limit_max'] + 0.0000001)\n","user_loan.drop(['loan_rate_min', 'loan_limit_max'], axis=1, inplace=True)\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Change loanapply_insert_time variable to datetime variable\n","user_loan['loanapply_insert_time'] = pd.to_datetime(user_loan['loanapply_insert_time'])\n","\n","# Create month variable from loanapply_insert_time\n","user_loan['month'] = user_loan['loanapply_insert_time'].dt.month\n","\n","# Filter test data for month = 6\n","test_data = user_loan[user_loan['month'] == 6]\n","\n","# Filter remaining data for months 3, 4, and 5\n","remaining_data = user_loan[(user_loan['month'] == 3) | (user_loan['month'] == 4) | (user_loan['month'] == 5)]\n","\n","# Split remaining data into train and validation data in 80:20 ratio\n","train_data, valid_data = train_test_split(remaining_data, test_size=0.2, random_state=42)\n","\n","# Print train_data, valid_data, and test_data\n","print(train_data)\n","print(valid_data)\n","print(test_data)\n"]}]},{"cell_type":"code","source":["question = f\"\"\"\n","\n","Please summarize the given code in the form of an data processing report, excluding the library import process.\n","Add subheadings to each code.\n","\n","code: {final_answer}\n","report:\n","\"\"\"\n","final_response = get_completion(question)\n","print(final_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FuO8gZltZk15","outputId":"803a6bb2-9f2c-43f0-97eb-2b74865f8683","executionInfo":{"status":"ok","timestamp":1695756611150,"user_tz":-540,"elapsed":51006,"user":{"displayName":"이채윤","userId":"10158698688563022551"}}},"id":"FuO8gZltZk15","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data Processing Report:\n","\n","1. Deleting Rows with Null Values in 'loan_limit' Column:\n","   - Rows in the 'loan_result' dataframe where the 'loan_limit' column has null values are dropped.\n","\n","2. Converting 'loanapply_insert_time' Column to Datetime Format:\n","   - The 'loanapply_insert_time' column in the 'loan_result' dataframe is converted to datetime format.\n","\n","3. Deleting Rows with 'bank_id' Value of 16:\n","   - Rows in the 'loan_result' dataframe where the 'bank_id' column has a value of 16 are dropped.\n","\n","4. Data Cleaning and Transformation on 'user_spec' DataFrame:\n","   - 'gender' column is dropped from the 'user_spec' dataframe.\n","   - 'insert_time' column is converted to datetime format.\n","   - 'company_enter_month' column is converted to string format and modified to have a specific format.\n","   - Missing values in 'company_enter_month' column are replaced with NaN values.\n","   - Missing values in 'company_enter_month' column are filled with the first non-null value for each user.\n","   - Missing values in 'birth_year' column are filled with the first non-null value for each user.\n","\n","5. Handling Missing Values and Data Transformation on 'user_spec' DataFrame:\n","   - Missing values in 'existing_loan_amt' and 'existing_loan_cnt' columns are replaced with 0.\n","   - Rows with missing values in 'income_type' column are dropped.\n","   - Missing values in 'yearly_income' column are filled with the mean value for each user.\n","   - 'rehabilitation' column is created based on conditions using other columns.\n","   - 'personal_rehabilitation_yn' and 'personal_rehabilitation_complete_yn' columns are dropped.\n","   - 'credit_score' column is filled with the mean value for each user.\n","   - 'unique_credit_scores' column is created to count the number of unique credit scores for each user.\n","   - Missing values in 'credit_score' column are filled based on conditions using 'unique_credit_scores' column.\n","   - 'unique_credit_scores' column is dropped.\n","   - Data types of certain columns are changed to categorical.\n","\n","6. Splitting Data and Training XGBoost Model:\n","   - Data is split into train and test sets based on the availability of 'credit_score' values.\n","   - XGBoost regressor model is trained using the train set.\n","   - Predictions are made for the test set using the trained model.\n","   - Predicted 'credit_score' values are added to the test set.\n","   - Train and test sets are concatenated to form the updated 'user_spec' dataframe.\n","\n","7. Creating Age Clusters:\n","   - 'cluster_age' column is created based on age ranges.\n","   - Missing values in 'cluster_age' column are filled with a default value.\n","   - Data types of certain columns are changed to categorical.\n","\n","8. Training XGBoost Classifier for Age Prediction:\n","   - Data is split into train and test sets based on the availability of 'age' values.\n","   - XGBoost classifier model is trained using the train set.\n","   - Predictions are made for the test set using the trained model.\n","   - Predicted 'cluster_age' values are added to the original 'user_spec' dataframe.\n","\n","9. Filling Missing Age Values:\n","   - Missing values in 'age' column are filled based on the predicted 'cluster_age' values.\n","   - 'cluster_age' column is dropped.\n","\n","10. Imputing Missing Values using IterativeImputer:\n","    - Certain columns are excluded from the imputation process.\n","    - IterativeImputer is used with ExtraTreesRegressor as the estimator to impute missing values.\n","    - Imputed values are stored in the 'result' dataframe.\n","\n","11. Updating 'user_spec' DataFrame with Imputed Values:\n","    - 'existing_loan_amt' and 'employment_period' columns are updated with the imputed values.\n","\n","12. Clustering Banks based on Loan Features:\n","    - 'purpose' column values are replaced with more descriptive labels.\n","    - 'user_spec' and 'loan_result' dataframes are merged on 'application_id'.\n","    - Rows with null values in 'loan_limit' column are dropped.\n","    - Features for clustering are selected from the merged dataframe.\n","    - KMeans clustering is performed on the selected features.\n","    - 'bank_cluster' column is added to the merged dataframe.\n","    - 'bank_id' and 'product_id' columns are dropped.\n","\n","13. Calculating Loan Rate and Loan Limit Percentages:\n","    - 'loan_rate_min' column is calculated as the minimum loan rate for each 'application_id'.\n","    - 'loan_rate_per' column is calculated as the ratio of 'loan_rate_min' to 'loan_rate'.\n","    - 'loan_limit_max' column is calculated as the maximum loan limit for each 'application_id'.\n","    - 'loan_limit_per' column is calculated as the ratio of 'loan_limit' to 'loan_limit_max'.\n","    - 'loan_rate_min' and 'loan_limit_max' columns are dropped.\n","\n","14. Splitting Data based on Loan Application Month:\n","    - 'loanapply_insert_time' column is converted to datetime format.\n","    - 'month' column is created from 'loanapply_insert_time'.\n","    - Test data for the month of June is separated.\n","    - Remaining data for the months of March, April, and May is separated.\n","    - Remaining data is split into train and validation sets.\n","\n","15. Final Report:\n","    - The train, validation, and test data are printed.\n"]}]},{"cell_type":"code","source":["question2 = f\"\"\"\n","\n","Translate given code summary analysis report into Korean.\n","\n","code summary analysis report: {final_response}\n","\n","\"\"\"\n","response_translate = get_completion(question2)\n","print(response_translate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdqu72eRdFR-","outputId":"3e0ce075-fdb2-425e-eace-209779207aa4","executionInfo":{"status":"ok","timestamp":1695756875876,"user_tz":-540,"elapsed":80766,"user":{"displayName":"이채윤","userId":"10158698688563022551"}}},"id":"wdqu72eRdFR-","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 처리 보고서:\n","\n","1. 'loan_limit' 열에서 Null 값이 있는 행 삭제:\n","   - 'loan_result' 데이터프레임에서 'loan_limit' 열에 Null 값이 있는 행이 삭제됩니다.\n","\n","2. 'loanapply_insert_time' 열을 날짜 및 시간 형식으로 변환:\n","   - 'loan_result' 데이터프레임의 'loanapply_insert_time' 열이 날짜 및 시간 형식으로 변환됩니다.\n","\n","3. 'bank_id' 값이 16인 행 삭제:\n","   - 'loan_result' 데이터프레임에서 'bank_id' 열의 값이 16인 행이 삭제됩니다.\n","\n","4. 'user_spec' 데이터프레임의 데이터 정리 및 변환:\n","   - 'gender' 열이 'user_spec' 데이터프레임에서 삭제됩니다.\n","   - 'insert_time' 열이 날짜 및 시간 형식으로 변환됩니다.\n","   - 'company_enter_month' 열이 문자열 형식으로 변환되고 특정 형식으로 수정됩니다.\n","   - 'company_enter_month' 열의 결측값은 NaN 값으로 대체됩니다.\n","   - 'company_enter_month' 열의 결측값은 각 사용자에 대해 첫 번째 비결측값으로 채워집니다.\n","   - 'birth_year' 열의 결측값은 각 사용자에 대해 첫 번째 비결측값으로 채워집니다.\n","\n","5. 'user_spec' 데이터프레임의 결측값 처리 및 데이터 변환:\n","   - 'existing_loan_amt' 및 'existing_loan_cnt' 열의 결측값은 0으로 대체됩니다.\n","   - 'income_type' 열의 결측값이 있는 행이 삭제됩니다.\n","   - 'yearly_income' 열의 결측값은 각 사용자에 대한 평균값으로 채워집니다.\n","   - 다른 열을 사용하여 조건에 따라 'rehabilitation' 열이 생성됩니다.\n","   - 'personal_rehabilitation_yn' 및 'personal_rehabilitation_complete_yn' 열이 삭제됩니다.\n","   - 'credit_score' 열은 각 사용자에 대한 평균값으로 채워집니다.\n","   - 'unique_credit_scores' 열은 각 사용자의 고유한 신용 점수 수를 계산하기 위해 생성됩니다.\n","   - 'credit_score' 열의 결측값은 'unique_credit_scores' 열을 사용하여 조건에 따라 채워집니다.\n","   - 'unique_credit_scores' 열이 삭제됩니다.\n","   - 특정 열의 데이터 유형이 범주형으로 변경됩니다.\n","\n","6. 데이터 분할 및 XGBoost 모델 학습:\n","   - 'credit_score' 값의 유무에 따라 데이터가 학습 및 테스트 세트로 분할됩니다.\n","   - XGBoost 회귀 모델이 학습 세트를 사용하여 학습됩니다.\n","   - 학습된 모델을 사용하여 테스트 세트에 대한 예측이 수행됩니다.\n","   - 예측된 'credit_score' 값이 테스트 세트에 추가됩니다.\n","   - 학습 및 테스트 세트가 결합되어 업데이트된 'user_spec' 데이터프레임이 형성됩니다.\n","\n","7. 나이 클러스터 생성:\n","   - 나이 범위에 기반하여 'cluster_age' 열이 생성됩니다.\n","   - 'cluster_age' 열의 결측값은 기본값으로 채워집니다.\n","   - 특정 열의 데이터 유형이 범주형으로 변경됩니다.\n","\n","8. 나이 예측을 위한 XGBoost 분류기 학습:\n","   - 'age' 값의 유무에 따라 데이터가 학습 및 테스트 세트로 분할됩니다.\n","   - XGBoost 분류기 모델이 학습 세트를 사용하여 학습됩니다.\n","   - 학습된 모델을 사용하여 테스트 세트에 대한 예측이 수행됩니다.\n","   - 예측된 'cluster_age' 값이 원래 'user_spec' 데이터프레임에 추가됩니다.\n","\n","9. 결측값이 있는 나이 값 채우기:\n","   - 'age' 열의 결측값은 예측된 'cluster_age' 값에 기반하여 채워집니다.\n","   - 'cluster_age' 열이 삭제됩니다.\n","\n","10. IterativeImputer를 사용하여 결측값 보완:\n","    - 일부 열은 보완 과정에서 제외됩니다.\n","    - ExtraTreesRegressor를 추정기로 사용하여 IterativeImputer가 결측값을 보완하는 데 사용됩니다.\n","    - 보완된 값은 'result' 데이터프레임에 저장됩니다.\n","\n","11. 보완된 값으로 'user_spec' 데이터프레임 업데이트:\n","    - 'existing_loan_amt' 및 'employment_period' 열이 보완된 값으로 업데이트됩니다.\n","\n","12. 대출 특징에 따른 은행 클러스터링:\n","    - 'purpose' 열의 값은 더 구체적인 레이블로 대체됩니다.\n","    - 'user_spec' 및 'loan_result' 데이터프레임이 'application_id'를 기준으로 병합됩니다.\n","    - 'loan_limit' 열에 결측값이 있는 행이 삭제됩니다.\n","    - 클러스터링에 사용할 특징이 병합된 데이터프레임에서 선택됩니다.\n","    - 선택된 특징에 대해 KMeans 클러스터링이 수행됩니다.\n","    - 'bank_cluster' 열이 병합된 데이터프레임에 추가됩니다.\n","    - 'bank_id' 및 'product_id' 열이 삭제됩니다.\n","\n","13. 대출 이율 및 대출 한도 비율 계산:\n","    - 'loan_rate_min' 열은 각 'application_id'에 대한 최소 대출 이율로 계산됩니다.\n","    - 'loan_rate_per' 열은 'loan_rate_min'을 'loan_rate'로 나눈 비율로 계산됩니다.\n","    - 'loan_limit_max' 열은 각 'application_id'에 대한 최대 대출 한도로 계산됩니다.\n","    - 'loan_limit_per' 열은 'loan_limit'을 'loan_limit_max'로 나눈 비율로 계산됩니다.\n","    - 'loan_rate_min' 및 'loan_limit_max' 열이 삭제됩니다.\n","\n","14. 대출 신청 월에 따른 데이터 분할:\n","    - 'loanapply_insert_time' 열이 날짜 및 시간 형식으로 변환됩니다.\n","    - 'month' 열이 'loanapply_insert_time'에서 생성됩니다.\n","    - 6월의 테스트 데이터가 분리됩니다.\n","    - 3월, 4월 및 5월의 나머지 데이터가 분리됩니다.\n","    - 나머지 데이터가 학습 및 검증 세트로 분할됩니다.\n","\n","15. 최종 보고서:\n","    - 학습, 검증 및 테스트 데이터가 출력됩니다.\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}